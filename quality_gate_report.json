{
  "timestamp": 1754539186.3755314,
  "execution_time": 9.856699466705322,
  "passed": 8,
  "failed": 5,
  "pass_rate": 61.53846153846154,
  "overall_status": "\u274c QUALITY GATES FAILED (Critical issues)",
  "detailed_results": {
    "test_quantum_planner": {
      "status": "PASSED",
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /root/repo/venv/bin/python\ncachedir: .pytest_cache\nrootdir: /root/repo\nconfigfile: pytest.ini\ncollecting ... collected 2 items\n\ntests/unit/test_quantum_planner.py::TestQuantumTask::test_quantum_task_creation PASSED [ 50%]\ntests/unit/test_quantum_planner.py::TestQuantumTask::test_collapse_state PASSED [100%]\n\n============================== 2 passed in 0.07s ===============================\n",
      "stderr": "",
      "returncode": 0
    },
    "test_quantum_security": {
      "status": "PASSED",
      "stdout": "============================= test session starts ==============================\nplatform linux -- Python 3.12.3, pytest-8.4.1, pluggy-1.6.0 -- /root/repo/venv/bin/python\ncachedir: .pytest_cache\nrootdir: /root/repo\nconfigfile: pytest.ini\ncollecting ... collected 5 items\n\ntests/unit/test_quantum_security.py::TestQuantumRandomGenerator::test_initialization PASSED [ 20%]\ntests/unit/test_quantum_security.py::TestQuantumRandomGenerator::test_generate_secure_bytes PASSED [ 40%]\ntests/unit/test_quantum_security.py::TestQuantumRandomGenerator::test_generate_secure_bytes_error PASSED [ 60%]\ntests/unit/test_quantum_security.py::TestQuantumRandomGenerator::test_generate_quantum_key PASSED [ 80%]\ntests/unit/test_quantum_security.py::TestQuantumRandomGenerator::test_entropy_pool_management PASSED [100%]\n\n============================== 5 passed in 0.21s ===============================\n",
      "stderr": "",
      "returncode": 0
    },
    "test_core_imports": {
      "status": "FAILED",
      "stdout": "",
      "stderr": "bash: -c: line 1: unexpected EOF while looking for matching `\"'\n",
      "returncode": 2
    },
    "security_secrets": {
      "status": "PASSED",
      "stdout": "src/photonic_foundry/__init__.py:from .quantum_security import QuantumSecurityManager, QuantumSecurityToken, SecurityLevel, SecurityConstraint\nsrc/photonic_foundry/__init__.py:    \"QuantumSecurityToken\",\nsrc/photonic_foundry/api/server.py:## Key Features\nsrc/photonic_foundry/core_enhanced.py:            cached_data = cache.get_by_key(model_hash)\nsrc/photonic_foundry/database/cache.py:    key: str\nsrc/photonic_foundry/database/cache.py:            'key': self.key,\nsrc/photonic_foundry/database/cache.py:            key=data['key'],\nsrc/photonic_foundry/database/cache.py:            for key, entry_data in data.items():\nsrc/photonic_foundry/database/cache.py:                metadata[key] = CacheEntry.from_dict(entry_data)\nsrc/photonic_foundry/database/cache.py:                key: entry.to_dict() \nsrc/photonic_foundry/database/cache.py:                for key, entry in self.metadata.items()\nsrc/photonic_foundry/database/cache.py:    def _generate_key(self, data: Any) -> str:\nsrc/photonic_foundry/database/cache.py:        \"\"\"Generate cache key from data.\"\"\"\nsrc/photonic_foundry/database/cache.py:            content = json.dumps(data, sort_keys=True)\nsrc/photonic_foundry/database/cache.py:    def _get_file_path(self, key: str, extension: str = \".pkl\") -> Path:\nsrc/photonic_foundry/database/cache.py:        \"\"\"Get file path for cache key.\"\"\"\nsrc/photonic_foundry/database/cache.py:        return self.cache_dir / f\"{key}{extension}\"\nsrc/photonic_foundry/database/cache.py:            expired_keys = []\nsrc/photonic_foundry/database/cache.py:            for key, entry in self.metadata.items():\nsrc/photonic_foundry/database/cache.py:                    expired_keys.append(key)\nsrc/photonic_foundry/database/cache.py:            for key in expired_keys:\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:                    key=lambda x: (x[1].access_count, x[1].accessed_at)\nsrc/photonic_foundry/database/cache.py:                for key, _ in sorted_entries[:excess_count]:\nsrc/photonic_foundry/database/cache.py:                    self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:    def _remove_entry(self, key: str):\nsrc/photonic_foundry/database/cache.py:        if key in self.metadata:\nsrc/photonic_foundry/database/cache.py:            entry = self.metadata[key]\nsrc/photonic_foundry/database/cache.py:            del self.metadata[key]\nsrc/photonic_foundry/database/cache.py:    def _update_access(self, key: str):\nsrc/photonic_foundry/database/cache.py:        if key in self.metadata:\nsrc/photonic_foundry/database/cache.py:            entry = self.metadata[key]\nsrc/photonic_foundry/database/cache.py:            for key in list(self.metadata.keys()):\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:        key = self._generate_key(circuit_data)\nsrc/photonic_foundry/database/cache.py:            file_path = self._get_file_path(key, \".json\")\nsrc/photonic_foundry/database/cache.py:                self.metadata[key] = CacheEntry(\nsrc/photonic_foundry/database/cache.py:                    key=key,\nsrc/photonic_foundry/database/cache.py:                logger.debug(f\"Cached circuit with key: {key}\")\nsrc/photonic_foundry/database/cache.py:        return key\nsrc/photonic_foundry/database/cache.py:        key = self._generate_key(circuit_data)\nsrc/photonic_foundry/database/cache.py:            if key not in self.metadata:\nsrc/photonic_foundry/database/cache.py:            entry = self.metadata[key]\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:                self._update_access(key)\nsrc/photonic_foundry/database/cache.py:                logger.debug(f\"Retrieved cached circuit with key: {key}\")\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:    def get_by_key(self, key: str) -> Optional[Dict[str, Any]]:\nsrc/photonic_foundry/database/cache.py:        \"\"\"Get cached circuit by key.\"\"\"\nsrc/photonic_foundry/database/cache.py:            if key not in self.metadata:\nsrc/photonic_foundry/database/cache.py:            entry = self.metadata[key]\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:                self._update_access(key)\nsrc/photonic_foundry/database/cache.py:            for key, entry in self.metadata.items():\nsrc/photonic_foundry/database/cache.py:                    'key': key,\nsrc/photonic_foundry/database/cache.py:        key = self._generate_key(component_spec)\nsrc/photonic_foundry/database/cache.py:            file_path = self._get_file_path(key, \".json\")\nsrc/photonic_foundry/database/cache.py:                self.metadata[key] = CacheEntry(\nsrc/photonic_foundry/database/cache.py:                    key=key,\nsrc/photonic_foundry/database/cache.py:                logger.debug(f\"Cached component with key: {key}\")\nsrc/photonic_foundry/database/cache.py:        return key\nsrc/photonic_foundry/database/cache.py:        key = self._generate_key(component_spec)\nsrc/photonic_foundry/database/cache.py:            if key not in self.metadata:\nsrc/photonic_foundry/database/cache.py:            entry = self.metadata[key]\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/cache.py:                self._update_access(key)\nsrc/photonic_foundry/database/cache.py:                self._remove_entry(key)\nsrc/photonic_foundry/database/connection.py:                id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/connection.py:                id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/connection.py:                id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/connection.py:                FOREIGN KEY (circuit_id) REFERENCES circuits (id)\nsrc/photonic_foundry/database/connection.py:                id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/connection.py:                id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/connection.py:                FOREIGN KEY (circuit_id) REFERENCES circuits (id)\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            FOREIGN KEY (circuit_id) REFERENCES circuits (id) ON DELETE CASCADE\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            FOREIGN KEY (circuit_id) REFERENCES circuits (id) ON DELETE CASCADE\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            config_key TEXT NOT NULL UNIQUE,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            id INTEGER PRIMARY KEY AUTOINCREMENT,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            cache_key TEXT NOT NULL UNIQUE,\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:        \"CREATE INDEX IF NOT EXISTS idx_system_config_key ON system_config (config_key);\",\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:        \"CREATE INDEX IF NOT EXISTS idx_cache_key ON cache_metadata (cache_key);\"\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:        for key, value, type_name, description in initial_config:\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:                \"INSERT OR IGNORE INTO system_config (config_key, config_value, config_type, description) VALUES (?, ?, ?, ?)\",\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:                (key, value, type_name, description)\nsrc/photonic_foundry/database/migrations/001_initial_schema.py:            executed_statements.append(f\"Config: {key} = {value}\")\nsrc/photonic_foundry/database/models.py:        circuit_str = json.dumps(self.circuit_data, sort_keys=True)\nsrc/photonic_foundry/database/models.py:            return list(self.component_library.keys())\nsrc/photonic_foundry/error_handling.py:        elif isinstance(error, (KeyError, AttributeError)):\nsrc/photonic_foundry/error_handling.py:        for key, value in sanitized_inputs.items():\nsrc/photonic_foundry/error_handling.py:                if 'size' in key:\nsrc/photonic_foundry/error_handling.py:                    sanitized_inputs[key] = 1\nsrc/photonic_foundry/error_handling.py:                elif 'count' in key:\nsrc/photonic_foundry/error_handling.py:                    sanitized_inputs[key] = 0\nsrc/photonic_foundry/error_handling.py:                elif 'name' in key:\nsrc/photonic_foundry/error_handling.py:                    sanitized_inputs[key] = 'default'\nsrc/photonic_foundry/error_handling.py:        for key, value in inputs.items():\nsrc/photonic_foundry/error_handling.py:                sanitized[key] = DataSanitizer.sanitize_string(value)\nsrc/photonic_foundry/error_handling.py:                sanitized[key] = DataSanitizer.sanitize_number(value)\nsrc/photonic_foundry/error_handling.py:                sanitized[key] = DataSanitizer.sanitize_list(value)\nsrc/photonic_foundry/error_handling.py:                sanitized[key] = value\nsrc/photonic_foundry/error_handling.py:            for key, default_value in defaults.items():\nsrc/photonic_foundry/error_handling.py:                if key not in result or result[key] is None:\nsrc/photonic_foundry/error_handling.py:                    result[key] = default_value\nsrc/photonic_foundry/models/simple_mlp.py:    for key, value in complexity.items():\nsrc/photonic_foundry/models/simple_mlp.py:        if key != 'layer_details':\nsrc/photonic_foundry/models/simple_mlp.py:            print(f\"  {key}: {value}\")\nsrc/photonic_foundry/performance.py:    def get(self, key: str) -> Optional[Any]:\nsrc/photonic_foundry/performance.py:            if key in self.cache:\nsrc/photonic_foundry/performance.py:                value = self.cache.pop(key)\nsrc/photonic_foundry/performance.py:                self.cache[key] = value\nsrc/photonic_foundry/performance.py:    def put(self, key: str, value: Any, size_mb: float = 0.1):\nsrc/photonic_foundry/performance.py:            if key in self.cache:\nsrc/photonic_foundry/performance.py:                old_size = self.cache[key].get('_size_mb', 0.1)\nsrc/photonic_foundry/performance.py:                del self.cache[key]\nsrc/photonic_foundry/performance.py:            self.cache[key] = cache_item\nsrc/photonic_foundry/performance.py:            key, item = self.cache.popitem(last=False)\nsrc/photonic_foundry/performance.py:        cache_key = f\"optimized_{circuit_hash}_{optimization_level}\"\nsrc/photonic_foundry/performance.py:        cached_result = self.cache.get(cache_key)\nsrc/photonic_foundry/performance.py:            logger.debug(f\"Cache hit for circuit optimization: {cache_key}\")\nsrc/photonic_foundry/performance.py:        self.cache.put(cache_key, optimized_circuit, size_mb=0.5)\nsrc/photonic_foundry/scaling.py:    def get(self, key: str) -> Optional[Any]:\nsrc/photonic_foundry/scaling.py:            # Check if key exists and is not expired\nsrc/photonic_foundry/scaling.py:            if (key in self.cache and \nsrc/photonic_foundry/scaling.py:                current_time - self.creation_times.get(key, 0) < self.ttl_seconds):\nsrc/photonic_foundry/scaling.py:                self.access_counts[key] = self.access_counts.get(key, 0) + 1\nsrc/photonic_foundry/scaling.py:                self.access_times[key] = current_time\nsrc/photonic_foundry/scaling.py:                self.recent_accesses.append(key)\nsrc/photonic_foundry/scaling.py:                return self.cache[key]\nsrc/photonic_foundry/scaling.py:            elif key in self.cache:\nsrc/photonic_foundry/scaling.py:                self._remove_item(key)\nsrc/photonic_foundry/scaling.py:    def put(self, key: str, value: Any) -> bool:\nsrc/photonic_foundry/scaling.py:            if len(self.cache) >= self.max_size and key not in self.cache:\nsrc/photonic_foundry/scaling.py:            self.cache[key] = value\nsrc/photonic_foundry/scaling.py:            self.access_counts[key] = 1\nsrc/photonic_foundry/scaling.py:            self.access_times[key] = current_time\nsrc/photonic_foundry/scaling.py:            self.creation_times[key] = current_time\nsrc/photonic_foundry/scaling.py:            self.recent_accesses.append(key)\nsrc/photonic_foundry/scaling.py:        for key in self.cache:\nsrc/photonic_foundry/scaling.py:            access_count = self.access_counts.get(key, 1)\nsrc/photonic_foundry/scaling.py:            last_access = self.access_times.get(key, 0)\nsrc/photonic_foundry/scaling.py:            age = current_time - self.creation_times.get(key, current_time)\nsrc/photonic_foundry/scaling.py:            scores[key] = frequency_score + recency_score - age_penalty\nsrc/photonic_foundry/scaling.py:        evict_key = min(scores, key=scores.get)\nsrc/photonic_foundry/scaling.py:        self._remove_item(evict_key)\nsrc/photonic_foundry/scaling.py:    def _remove_item(self, key: str):\nsrc/photonic_foundry/scaling.py:        self.cache.pop(key, None)\nsrc/photonic_foundry/scaling.py:        self.access_counts.pop(key, None)\nsrc/photonic_foundry/scaling.py:        self.access_times.pop(key, None)\nsrc/photonic_foundry/scaling.py:        self.creation_times.pop(key, None)\nsrc/photonic_foundry/scaling.py:            unique_keys = len(self.access_counts)\nsrc/photonic_foundry/scaling.py:            recent_keys = list(self.recent_accesses)\nsrc/photonic_foundry/scaling.py:            hits = sum(1 for key in recent_keys if key in self.cache)\nsrc/photonic_foundry/scaling.py:            hit_rate = hits / len(recent_keys) if recent_keys else 0\nsrc/photonic_foundry/scaling.py:                'unique_keys': unique_keys,\nsrc/photonic_foundry/scaling.py:                'avg_accesses_per_key': total_accesses / max(unique_keys, 1),\nsrc/photonic_foundry/scaling.py:        cache_key = self._generate_cache_key(workload_type, data, kwargs)\nsrc/photonic_foundry/scaling.py:        cached_result = self.adaptive_cache.get(cache_key)\nsrc/photonic_foundry/scaling.py:        self.adaptive_cache.put(cache_key, optimized_data)\nsrc/photonic_foundry/scaling.py:    def _generate_cache_key(self, workload_type: str, data: Any, kwargs: Dict) -> str:\nsrc/photonic_foundry/scaling.py:        \"\"\"Generate cache key for workload.\"\"\"\nsrc/photonic_foundry/scaling.py:        key_components = [workload_type]\nsrc/photonic_foundry/scaling.py:            key_components.append(str(data.shape) + str(data.dtype))\nsrc/photonic_foundry/scaling.py:            key_components.append(f\"list_{len(data)}\")\nsrc/photonic_foundry/scaling.py:            key_components.append(str(type(data)))\nsrc/photonic_foundry/scaling.py:            key_components.append(f\"{k}:{v}\")\nsrc/photonic_foundry/scaling.py:        key_string = \"_\".join(key_components)\nsrc/photonic_foundry/scaling.py:        return hashlib.md5(key_string.encode()).hexdigest()[:16]\nsrc/photonic_foundry/scaling.py:            'most_effective_optimization': max(optimization_counts, key=optimization_counts.get) if optimization_counts else None\nsrc/photonic_foundry/security.py:            (r'password\\s*=\\s*[\"\\'][^\"\\']+[\"\\']', 'Hard-coded password'),\nsrc/photonic_foundry/security.py:            (r'api[_\\-]?key\\s*=\\s*[\"\\'][^\"\\']+[\"\\']', 'Hard-coded API key'),\nsrc/photonic_foundry/security.py:            (r'secret\\s*=\\s*[\"\\'][^\"\\']+[\"\\']', 'Hard-coded secret'),\nsrc/photonic_foundry/security.py:            (r'token\\s*=\\s*[\"\\'][^\"\\']+[\"\\']', 'Hard-coded token'),\nsrc/photonic_foundry/security.py:            # Check for hardcoded secrets in assignments\nsrc/photonic_foundry/security.py:                        if any(keyword in var_name for keyword in ['password', 'secret', 'key', 'token']):\nsrc/photonic_foundry/security.py:                        description=f\"Large dictionary with {len(obj)} keys\",\nsrc/photonic_foundry/security.py:                for key, value in obj.items():\nsrc/photonic_foundry/security.py:            'AWS_SECRET_ACCESS_KEY', 'AZURE_CLIENT_SECRET', 'GCP_SERVICE_ACCOUNT_KEY',\nsrc/photonic_foundry/security.py:            'DATABASE_PASSWORD', 'API_KEY', 'SECRET_KEY', 'PRIVATE_KEY'\nsrc/photonic_foundry/security.py:                if len(value) > 20:  # Likely a real secret\nsrc/photonic_foundry/security.py:                        recommendation=\"Ensure secrets are properly secured\"\nsrc/photonic_foundry/security.py:        sensitive_files = ['.env', 'config.json', 'secrets.json', 'credentials.json']\nsrc/photonic_foundry/utils/advanced_optimizers.py:            return [{'zone_id': 0, 'components': list(placement.keys()), 'center': positions[0] if positions else (0, 0)}]\nsrc/photonic_foundry/utils/advanced_optimizers.py:            zone_components = list(placement.keys())[start_idx:end_idx]\nsrc/photonic_foundry/utils/optimizers.py:        sorted_connections = sorted(connections, key=lambda x: (x[0], x[1]))\nsrc/photonic_foundry/validation.py:            for key, value in data.items():\nsrc/photonic_foundry/validation.py:                self._check_dangerous_patterns(value, result, f\"{path}.{key}\")\nsrc/photonic_foundry/quantum_planner.py:        shared_resources = set(task_a.resources_required.keys()) & set(task_b.resources_required.keys())\nsrc/photonic_foundry/quantum_security.py:import secrets\nsrc/photonic_foundry/quantum_security.py:    quantum_key_distribution: bool = False\nsrc/photonic_foundry/quantum_security.py:class QuantumSecurityToken:\nsrc/photonic_foundry/quantum_security.py:    \"\"\"Quantum-enhanced security token.\"\"\"\nsrc/photonic_foundry/quantum_security.py:    token_id: str\nsrc/photonic_foundry/quantum_security.py:        \"\"\"Check if token is still valid.\"\"\"\nsrc/photonic_foundry/quantum_security.py:        \"\"\"Check if token has specific permission.\"\"\"\nsrc/photonic_foundry/quantum_security.py:        system_entropy = secrets.token_bytes(32)\nsrc/photonic_foundry/quantum_security.py:            measurement = secrets.randbits(1)\nsrc/photonic_foundry/quantum_security.py:        base_random = secrets.token_bytes(length)\nsrc/photonic_foundry/quantum_security.py:    def generate_quantum_key(self, key_size: int = 32) -> Tuple[bytes, str]:\nsrc/photonic_foundry/quantum_security.py:        \"\"\"Generate quantum-enhanced cryptographic key.\"\"\"\nsrc/photonic_foundry/quantum_security.py:        key_material = self.generate_secure_bytes(key_size)\nsrc/photonic_foundry/quantum_security.py:        key_fingerprint = hashlib.sha256(key_material).hexdigest()[:16]\nsrc/photonic_foundry/quantum_security.py:        logger.debug(f\"Generated quantum key with fingerprint: {key_fingerprint}\")\nsrc/photonic_foundry/quantum_security.py:        return key_material, key_fingerprint\nsrc/photonic_foundry/quantum_security.py:        self.key_cache = {}\nsrc/photonic_foundry/quantum_security.py:            'key_size': 32,\nsrc/photonic_foundry/quantum_security.py:    def encrypt_task_data(self, task: QuantumTask, data: bytes, key: bytes = None) -> Dict[str, Any]:\nsrc/photonic_foundry/quantum_security.py:        if key is None:\nsrc/photonic_foundry/quantum_security.py:            key, key_fingerprint = self.quantum_rng.generate_quantum_key()\nsrc/photonic_foundry/quantum_security.py:            key_fingerprint = hashlib.sha256(key).hexdigest()[:16]\nsrc/photonic_foundry/quantum_security.py:            algorithms.AES(key),\nsrc/photonic_foundry/quantum_security.py:            'key_fingerprint': key_fingerprint,\nsrc/photonic_foundry/quantum_security.py:    def decrypt_task_data(self, encrypted_package: Dict[str, Any], key: bytes) -> bytes:\nsrc/photonic_foundry/quantum_security.py:            # Verify key fingerprint\nsrc/photonic_foundry/quantum_security.py:            key_fingerprint = hashlib.sha256(key).hexdigest()[:16]\nsrc/photonic_foundry/quantum_security.py:            if key_fingerprint != encrypted_package['key_fingerprint']:\nsrc/photonic_foundry/quantum_security.py:                raise ValueError(\"Key fingerprint mismatch\")\nsrc/photonic_foundry/quantum_security.py:                algorithms.AES(key),\nsrc/photonic_foundry/quantum_security.py:    def generate_quantum_signature(self, data: bytes, private_key: bytes = None) -> str:\nsrc/photonic_foundry/quantum_security.py:        if private_key is None:\nsrc/photonic_foundry/quantum_security.py:            private_key, _ = self.quantum_rng.generate_quantum_key()\nsrc/photonic_foundry/quantum_security.py:        # Derive signing key\nsrc/photonic_foundry/quantum_security.py:        signing_key = kdf.derive(private_key)\nsrc/photonic_foundry/quantum_security.py:        signature = hmac.new(signing_key, data, hashlib.sha256).digest()\nsrc/photonic_foundry/quantum_security.py:    def verify_quantum_signature(self, data: bytes, signature: str, private_key: bytes) -> bool:\nsrc/photonic_foundry/quantum_security.py:            # Derive verification key\nsrc/photonic_foundry/quantum_security.py:            verification_key = kdf.derive(private_key)\nsrc/photonic_foundry/quantum_security.py:            expected_signature = hmac.new(verification_key, data, hashlib.sha256).digest()\nsrc/photonic_foundry/quantum_security.py:        self.active_tokens = {}\nsrc/photonic_foundry/quantum_security.py:    def create_security_token(self, user_id: str, permissions: List[str], \nsrc/photonic_foundry/quantum_security.py:                            validity_hours: float = 24.0) -> QuantumSecurityToken:\nsrc/photonic_foundry/quantum_security.py:        \"\"\"Create quantum-enhanced security token.\"\"\"\nsrc/photonic_foundry/quantum_security.py:        token_id = secrets.token_urlsafe(32)\nsrc/photonic_foundry/quantum_security.py:        token_data = f\"{user_id}:{token_id}:{time.time()}\".encode()\nsrc/photonic_foundry/quantum_security.py:        quantum_signature = self.cryptographer.generate_quantum_signature(token_data)\nsrc/photonic_foundry/quantum_security.py:        # Create token\nsrc/photonic_foundry/quantum_security.py:        token = QuantumSecurityToken(\nsrc/photonic_foundry/quantum_security.py:            token_id=token_id,\nsrc/photonic_foundry/quantum_security.py:        # Store active token\nsrc/photonic_foundry/quantum_security.py:        self.active_tokens[token_id] = token\nsrc/photonic_foundry/quantum_security.py:        self._audit_log(\"TOKEN_CREATED\", {\nsrc/photonic_foundry/quantum_security.py:            'token_id': token_id,\nsrc/photonic_foundry/quantum_security.py:        logger.info(f\"Created quantum security token for user: {user_id}\")\nsrc/photonic_foundry/quantum_security.py:        return token\nsrc/photonic_foundry/quantum_security.py:    def validate_security_token(self, token_id: str) -> Tuple[bool, Optional[QuantumSecurityToken]]:\nsrc/photonic_foundry/quantum_security.py:        \"\"\"Validate quantum security token.\"\"\"\nsrc/photonic_foundry/quantum_security.py:        if token_id not in self.active_tokens:\nsrc/photonic_foundry/quantum_security.py:            logger.warning(f\"Unknown token validation attempt: {token_id}\")\nsrc/photonic_foundry/quantum_security.py:        token = self.active_tokens[token_id]\nsrc/photonic_foundry/quantum_security.py:        if not token.is_valid():\nsrc/photonic_foundry/quantum_security.py:            logger.warning(f\"Expired token validation attempt: {token_id}\")\nsrc/photonic_foundry/quantum_security.py:            del self.active_tokens[token_id]\nsrc/photonic_foundry/quantum_security.py:        logger.debug(f\"Token validation successful: {token_id}\")\nsrc/photonic_foundry/quantum_security.py:        return True, token\nsrc/photonic_foundry/quantum_security.py:                            token: QuantumSecurityToken) -> Dict[str, Any]:\nsrc/photonic_foundry/quantum_security.py:        if not token.has_permission('execute_tasks'):\nsrc/photonic_foundry/quantum_security.py:                'token_id': token.token_id,\nsrc/photonic_foundry/quantum_security.py:                'security_level': token.security_level.value,\nsrc/photonic_foundry/quantum_security.py:                'token_id': token.token_id,\nsrc/photonic_foundry/quantum_security.py:                'active_tokens': len(self.active_tokens)\nsrc/photonic_foundry/quantum_security.py:        # Active token statistics\nsrc/photonic_foundry/quantum_security.py:        valid_tokens = [t for t in self.active_tokens.values() if t.is_valid()]\nsrc/photonic_foundry/quantum_security.py:        expired_tokens = len(self.active_tokens) - len(valid_tokens)\nsrc/photonic_foundry/quantum_security.py:        # Clean up expired tokens\nsrc/photonic_foundry/quantum_security.py:        expired_token_ids = [tid for tid, token in self.active_tokens.items() if not token.is_valid()]\nsrc/photonic_foundry/quantum_security.py:        for tid in expired_token_ids:\nsrc/photonic_foundry/quantum_security.py:            del self.active_tokens[tid]\nsrc/photonic_foundry/quantum_security.py:        for token in valid_tokens:\nsrc/photonic_foundry/quantum_security.py:            level = token.security_level.value\nsrc/photonic_foundry/quantum_security.py:            'active_tokens': len(valid_tokens),\nsrc/photonic_foundry/quantum_security.py:            'expired_tokens_cleaned': expired_tokens,\nsrc/photonic_foundry/quantum_resilience.py:        old_timestamps = [t for t in self.health_metrics.keys() if t < cutoff_time]\nsrc/photonic_foundry/quantum_resilience.py:        if isinstance(error, (SystemExit, KeyboardInterrupt)):\nsrc/photonic_foundry/quantum_optimizer.py:        # Cache key for results\nsrc/photonic_foundry/quantum_optimizer.py:        cache_key = self._generate_cache_key(circuit, parameter_bounds)\nsrc/photonic_foundry/quantum_optimizer.py:        if self.config.cache_intermediate_results and cache_key in self.cached_results:\nsrc/photonic_foundry/quantum_optimizer.py:            return self.cached_results[cache_key]\nsrc/photonic_foundry/quantum_optimizer.py:                self.cached_results[cache_key] = result\nsrc/photonic_foundry/quantum_optimizer.py:        best_result = min(results, key=lambda x: x.get('best_objective', float('inf')))\nsrc/photonic_foundry/quantum_optimizer.py:    def _generate_cache_key(self, circuit: PhotonicCircuit, \nsrc/photonic_foundry/quantum_optimizer.py:        \"\"\"Generate cache key for optimization results.\"\"\"\nsrc/photonic_foundry/quantum_optimizer.py:        key_data = f\"{circuit.name}_{len(circuit.layers)}_{circuit.total_components}_{str(parameter_bounds)}\"\nsrc/photonic_foundry/quantum_optimizer.py:        return hashlib.md5(key_data.encode()).hexdigest()\n",
      "stderr": "",
      "returncode": 0
    },
    "security_permissions": {
      "status": "PASSED",
      "stdout": "src/photonic_foundry/__init__.py\nsrc/photonic_foundry/api/__init__.py\nsrc/photonic_foundry/api/endpoints.py\nsrc/photonic_foundry/api/middleware.py\nsrc/photonic_foundry/api/schemas.py\n",
      "stderr": "",
      "returncode": 0
    },
    "quantum_security_demo": {
      "status": "PASSED",
      "stdout": "Quantum security: b'\\xb0|&\\xd2o\\xd8\\\\\\xbf'\n",
      "stderr": "",
      "returncode": 0
    },
    "performance_basic": {
      "status": "FAILED",
      "stdout": "",
      "stderr": "/bin/sh: 1: source: not found\n",
      "returncode": 127
    },
    "performance_optimization": {
      "status": "FAILED",
      "stdout": "",
      "stderr": "/bin/sh: 1: source: not found\n",
      "returncode": 127
    },
    "integration_workflow": {
      "status": "FAILED",
      "stdout": "",
      "stderr": "/bin/sh: 1: source: not found\n",
      "returncode": 127
    },
    "integration_database": {
      "status": "FAILED",
      "stdout": "",
      "stderr": "/bin/sh: 1: source: not found\n",
      "returncode": 127
    },
    "quality_syntax": {
      "status": "PASSED",
      "stdout": "All Python files compile successfully\n",
      "stderr": "find: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\nfind: \u2018python\u2019: No such file or directory\n",
      "returncode": 0
    },
    "quality_loc": {
      "status": "PASSED",
      "stdout": "Total lines of code: 905\n",
      "stderr": "",
      "returncode": 0
    },
    "quality_todos": {
      "status": "PASSED",
      "stdout": "TODO items found: 0\n",
      "stderr": "",
      "returncode": 0
    }
  }
}